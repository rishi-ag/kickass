{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pick a dictionary (or dictionaries) of your choice from the Harvard IV set, \n",
    "the Loughran-McDonald set, or some other of your choosing that you think may be relevant for the data you collected for Q4 of the previous problem set. Then conduct the following exercise:\n",
    "(a) Use the two methods above to score each document in your data.\n",
    "(b) Explore whether the scores diﬀer according to the meta data ﬁelds you gathered: for example, do diﬀerent speakers/sources/etc tend to receive a higher score than\n",
    "others?\n",
    "(c) Do the answers to the previous question depend on whether tf-idf weighting is applied or not? Why do you think there is (or is not) a diﬀerence in your answers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'xlrd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e39061deb365>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkickass\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'xlrd'"
     ]
    }
   ],
   "source": [
    "import kickass as ks\n",
    "import xlrd\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "fd = open(\"../data/project_successful_final_tech_sample.json\", \"r\")\n",
    "\n",
    "project_json = json.load(fd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ks_projects = ks.ProjectCollection(project_json, \"../data/stopwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cleaning documents---tokenizing words, removing stopwords, and stemming\n",
    "ks_projects.clean_docs(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import word list\n",
    "\n",
    "wordlist_excel = xlrd.open_workbook(\"../data/H4Wordlist.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wl_sheet = wordlist_excel.sheet_by_index(0)\n",
    "word_dict = dict()\n",
    "\n",
    "def pre_process(word):\n",
    "    word = re.sub(\"#\\d+\", \"\", word.lower())\n",
    "    word = ks.nltk.PorterStemmer().stem(word)\n",
    "    return word\n",
    "\n",
    "for i in range(wl_sheet.ncols):\n",
    "    word_dict[wl_sheet.col(i)[0].value] = [pre_process(cell.value.lower()) \\\n",
    "                                     for cell in wl_sheet.col(i)[1:] if cell.value != \"\"]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Evaluating the top 20 ranks based on word counts in different dictionaries\n",
    "ks_sentiment_count = {key: ks_projects.rank_count(word_dict[key], 20) \\\n",
    "                      for key in word_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in ks_sentiment_count.keys():\n",
    "    print key, ks_sentiment_count[key][0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Evaluating the top 20 ranks based on tfidf in different dictionaries\n",
    "ks_sentiment_tfifd = {key: ks_projects.rank_tfidf(word_dict[key], 20) \\\n",
    "                      for key in word_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in ks_sentiment_tfifd.keys():\n",
    "    print key, ks_sentiment_tfifd[key][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "   Looking at the data closely we realise that there is a difference in rankings of documents between the count and the tfidf methods. This is to be expected because tfidf reweights the count frequencies by how frequently they appear in all documents. \n",
    "   \n",
    "   Below we have highlighted the differences we came accross\n",
    "   \n",
    "   It appears that for our sample size of 100 the dictionaries of \"Active\" and \"Quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in ks_sentiment_count.keys():\n",
    "    \n",
    "    print \"Dictionary \" + key.upper()\n",
    "    print \"Ranking\" + \"\\t \\t\" + \"Count\" + \"\\t \\t\" + \"Tfidf\"\n",
    "    for i in range(len(ks_sentiment_count[key])):\n",
    "        if ks_sentiment_count[key][i][0] != ks_sentiment_tfifd[key][i][0]:\n",
    "            print(str(i+1)+ \"\\t \\t\" + str(ks_sentiment_count[key][i][0]) + \"\\t \\t\" + \\\n",
    "            str(ks_sentiment_tfifd[key][i][0]) )\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to break down the rankings based on if the project has higher than or lower than the median number of financial backers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regex = re.compile(\"\\d+\")\n",
    "\n",
    "med_backers_list = []\n",
    "backers = dict()\n",
    "\n",
    "for project in project_json:\n",
    "    backer = int(regex.findall(project[\"no_backers\"])[0])\n",
    "    med_backers_list.append(backer)\n",
    "    backers[project[\"id\"]]= backer\n",
    "\n",
    "med_backers = ks.np.median(med_backers_list)\n",
    "\n",
    "\n",
    "#add indicator variable if num backers if greater than median\n",
    "def med_ind(ranking):\n",
    "\n",
    "    for key in ranking.keys():\n",
    "        for project_doc in ranking[key]:\n",
    "            if backers[project_doc[0]] > med_backers:\n",
    "                project_doc.append(\"GreaterMedian\")\n",
    "            else:\n",
    "                project_doc.append(\"LessMedian\")\n",
    "    return ranking\n",
    "\n",
    "ks_sentiment_tfifd = med_ind(ks_sentiment_tfifd)\n",
    "ks_sentiment_count = med_ind(ks_sentiment_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_top_n(top, ranking):\n",
    "    \n",
    "    greater_than_list = []\n",
    "    less_than_list = []\n",
    "\n",
    "    for key in ranking.keys():\n",
    "        greater_than = 0\n",
    "        less_than = 0\n",
    "        for project_doc in ranking[key][0:top]:\n",
    "            if project_doc[2] == \"GreaterMedian\":\n",
    "                greater_than+= 1\n",
    "            else:\n",
    "                less_than += 1\n",
    "        greater_than_list.append(greater_than)\n",
    "        less_than_list.append(less_than)\n",
    "    return greater_than_list, less_than_list\n",
    "\n",
    "\n",
    "#Plot to compare TOP 10 ranked results by median backers indicator\n",
    "def plot_results(top, ranking, typer):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    n_groups = len(ks_sentiment_count.keys())\n",
    "    index = ks.np.arange(n_groups)\n",
    "    greater_than_list, less_than_list = compare_top_n(top,ranking)\n",
    "    bar_width = 0.35\n",
    "\n",
    "    opacity = 0.4\n",
    "\n",
    "    rects1 = plt.bar(index, greater_than_list, bar_width,\n",
    "                     alpha=opacity,\n",
    "                     color='b',\n",
    "                     label='GreaterThan')\n",
    "\n",
    "    rects2 = plt.bar(index + bar_width, less_than_list, bar_width,\n",
    "                     alpha=opacity,\n",
    "                     color='r',\n",
    "                     label='LessThan')\n",
    "\n",
    "    plt.xlabel('Dictionary')\n",
    "    plt.ylabel('')\n",
    "    plt.title('Freq by Median # Backers Indicator by Count for '+ typer)\n",
    "    plt.xticks(index + bar_width, ranking.keys() )\n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_results(10, ks_sentiment_count, \"Count Based Ranking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that when we compare the top 10 results breakdown of rankings based on if a project has more backers than the median is more or less even accross dictionaries except for the ACTIVE dictionary.\n",
    "\n",
    "However, if we consider the top 20 results, the differences become more stark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_results(20, ks_sentiment_count, \"Count Based Ranking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can clearly see that projects with more backers tend to have more occurrences across all dictionaries."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Plotting a similar graph for TFIDF based ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_results(10, ks_sentiment_tfifd, \"TFIDF Based Ranking\")\n",
    "plot_results(20, ks_sentiment_tfifd, \"TFIDF Based Ranking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected while the counts of rankings based on no of backers does not change across ranking types, what does change is the order of ranking of the project documents that we have demonstrated using a table in the previous section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
